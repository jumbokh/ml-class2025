{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2970526,"sourceType":"datasetVersion","datasetId":1820993}],"dockerImageVersionId":30152,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.058916,"end_time":"2021-12-25T16:07:56.468974","exception":false,"start_time":"2021-12-25T16:07:56.410058","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <center> ★ Machine Learning Project - Ad Budget Estimation ★\n#### <center> ***Domain: Automotive***","metadata":{"papermill":{"duration":0.056916,"end_time":"2021-12-25T16:07:56.585168","exception":false,"start_time":"2021-12-25T16:07:56.528252","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.05593,"end_time":"2021-12-25T16:07:56.696664","exception":false,"start_time":"2021-12-25T16:07:56.640734","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from IPython import display\ndisplay.Image('https://raw.githubusercontent.com/Masterx-AI/Project_Retail_Analysis_with_Walmart/main/Wallmart1.jpg')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-16T14:07:22.941146Z","iopub.execute_input":"2022-01-16T14:07:22.941467Z","iopub.status.idle":"2022-01-16T14:07:23.577106Z","shell.execute_reply.started":"2022-01-16T14:07:22.941427Z","shell.execute_reply":"2022-01-16T14:07:23.576187Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.056547,"end_time":"2021-12-25T16:07:56.923609","exception":false,"start_time":"2021-12-25T16:07:56.867062","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Description:\n\nOne of the leading retail stores in the US, Walmart, would like to predict the sales and demand accurately. There are certain events and holidays which impact sales on each day. There are sales data available for 45 stores of Walmart. The business is facing a challenge due to unforeseen demands and runs out of stock some times, due to the inappropriate machine learning algorithm. An ideal ML algorithm will predict demand accurately and ingest factors like economic conditions including CPI, Unemployment Index, etc.\n\nWalmart runs several promotional markdown events throughout the year. These markdowns precede prominent holidays, the four largest of all, which are the Super Bowl, Labour Day, Thanksgiving, and Christmas. The weeks including these holidays are weighted five times higher in the evaluation than non-holiday weeks. Part of the challenge presented by this competition is modeling the effects of markdowns on these holiday weeks in the absence of complete/ideal historical data. Historical sales data for 45 Walmart stores located in different regions are available.\n\nDataset Info:\\\nThis is the historical data that covers sales from 2010-02-05 to 2012-11-01, in the file Walmart_Store_sales. Within this file you will find the following fields:\\\n* Store - the store number\n* Date - the week of sales\n* Weekly_Sales -  sales for the given store\n* Holiday_Flag - whether the week is a special holiday week 1 – Holiday week 0 – Non-holiday week\n* Temperature - Temperature on the day of sale\n* Fuel_Price - Cost of fuel in the region\n* CPI – Prevailing consumer price index\n* Unemployment - Prevailing unemployment rate\n* Holiday Events\\\nSuper Bowl: 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13\\\nLabour Day: 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13\\\nThanksgiving: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13\\\nChristmas: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13\n\n### Acknowledgements\nThe dataset is taken from Kaggle.\n\n### Objective:\n- Understand the Dataset & cleanup (if required).\n- Build Regression models to predict the sales w.r.t a single & multiple feature.\n- Also evaluate the models & compare their respective scores like R2, RMSE, etc.","metadata":{"papermill":{"duration":0.056328,"end_time":"2021-12-25T16:07:57.037715","exception":false,"start_time":"2021-12-25T16:07:56.981387","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.057075,"end_time":"2021-12-25T16:07:57.152178","exception":false,"start_time":"2021-12-25T16:07:57.095103","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <center> Stractegic Plan of Action:","metadata":{"papermill":{"duration":0.057096,"end_time":"2021-12-25T16:07:57.266706","exception":false,"start_time":"2021-12-25T16:07:57.20961","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**We aim to solve the problem statement by creating a plan of action, Here are some of the necessary steps:**\n1. Data Exploration\n2. Exploratory Data Analysis (EDA)\n3. Data Pre-processing\n4. Data Manipulation\n5. Feature Selection/Extraction\n6. Predictive Modelling\n7. Project Outcomes & Conclusion","metadata":{"papermill":{"duration":0.056711,"end_time":"2021-12-25T16:07:57.381401","exception":false,"start_time":"2021-12-25T16:07:57.32469","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.058175,"end_time":"2021-12-25T16:07:57.497916","exception":false,"start_time":"2021-12-25T16:07:57.439741","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <center>1. Data Exploration","metadata":{"papermill":{"duration":0.056702,"end_time":"2021-12-25T16:07:57.61225","exception":false,"start_time":"2021-12-25T16:07:57.555548","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Importing the basic librarires\n\nimport os\nimport math\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom IPython.display import display\n\n#from brokenaxes import brokenaxes\nfrom statsmodels.formula import api\nfrom sklearn.feature_selection import RFE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [10,6]\n\nimport warnings \nwarnings.filterwarnings('ignore')","metadata":{"papermill":{"duration":1.546432,"end_time":"2021-12-25T16:07:59.21597","exception":false,"start_time":"2021-12-25T16:07:57.669538","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-01-16T14:07:23.578704Z","iopub.execute_input":"2022-01-16T14:07:23.579242Z","iopub.status.idle":"2022-01-16T14:07:23.589295Z","shell.execute_reply.started":"2022-01-16T14:07:23.579203Z","shell.execute_reply":"2022-01-16T14:07:23.588454Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Importing the dataset\n\ndf = pd.read_csv('../input/walmart-dataset/Walmart.csv')\n\n#df.drop(['car name'], axis=1, inplace=True)\ndisplay(df.head())\n\noriginal_df = df.copy(deep=True)\n\nprint('\\n\\033[1mInference:\\033[0m The Datset consists of {} features & {} samples.'.format(df.shape[1], df.shape[0]))","metadata":{"papermill":{"duration":0.104332,"end_time":"2021-12-25T16:07:59.376566","exception":false,"start_time":"2021-12-25T16:07:59.272234","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:47:44.643202Z","iopub.execute_input":"2021-12-26T08:47:44.645519Z","iopub.status.idle":"2021-12-26T08:47:44.699501Z","shell.execute_reply.started":"2021-12-26T08:47:44.645468Z","shell.execute_reply":"2021-12-26T08:47:44.698511Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reframing the columns\n\ndf.Date=pd.to_datetime(df.Date)\n\ndf['weekday'] = df.Date.dt.weekday\ndf['month'] = df.Date.dt.month\ndf['year'] = df.Date.dt.year\n\n# df['Monthly_Quarter'] = df.month.map({1:'Q1',2:'Q1',3:'Q1',4:'Q2',5:'Q2',6:'Q2',7:'Q3',\n#                                       8:'Q3',9:'Q3',10:'Q4',11:'Q4',12:'Q4'})\n\ndf.drop(['Date'], axis=1, inplace=True)#,'month'\n\ntarget = 'Weekly_Sales'\nfeatures = [i for i in df.columns if i not in [target]]\noriginal_df = df.copy(deep=True)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-26T08:47:44.700614Z","iopub.execute_input":"2021-12-26T08:47:44.700836Z","iopub.status.idle":"2021-12-26T08:47:44.741949Z","shell.execute_reply.started":"2021-12-26T08:47:44.700807Z","shell.execute_reply":"2021-12-26T08:47:44.740842Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Checking the dtypes of all the columns\n\ndf.info()","metadata":{"papermill":{"duration":0.079235,"end_time":"2021-12-25T16:07:59.51375","exception":false,"start_time":"2021-12-25T16:07:59.434515","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:47:44.744374Z","iopub.execute_input":"2021-12-26T08:47:44.744684Z","iopub.status.idle":"2021-12-26T08:47:44.762898Z","shell.execute_reply.started":"2021-12-26T08:47:44.744651Z","shell.execute_reply":"2021-12-26T08:47:44.762168Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Checking number of unique rows in each feature\n\ndf.nunique().sort_values()","metadata":{"papermill":{"duration":0.071448,"end_time":"2021-12-25T16:07:59.643186","exception":false,"start_time":"2021-12-25T16:07:59.571738","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:47:44.764037Z","iopub.execute_input":"2021-12-26T08:47:44.764262Z","iopub.status.idle":"2021-12-26T08:47:44.775539Z","shell.execute_reply.started":"2021-12-26T08:47:44.764233Z","shell.execute_reply":"2021-12-26T08:47:44.774511Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Checking number of unique rows in each feature\n\nnu = df[features].nunique().sort_values()\nnf = []; cf = []; nnf = 0; ncf = 0; #numerical & categorical features\n\nfor i in range(df[features].shape[1]):\n    if nu.values[i]<=45:cf.append(nu.index[i])\n    else: nf.append(nu.index[i])\n\nprint('\\n\\033[1mInference:\\033[0m The Datset has {} numerical & {} categorical features.'.format(len(nf),len(cf)))","metadata":{"papermill":{"duration":0.07308,"end_time":"2021-12-25T16:07:59.774046","exception":false,"start_time":"2021-12-25T16:07:59.700966","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:47:44.777078Z","iopub.execute_input":"2021-12-26T08:47:44.777647Z","iopub.status.idle":"2021-12-26T08:47:44.790833Z","shell.execute_reply.started":"2021-12-26T08:47:44.777614Z","shell.execute_reply":"2021-12-26T08:47:44.789901Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Checking the stats of all the columns\n\ndisplay(df.describe())","metadata":{"papermill":{"duration":0.09296,"end_time":"2021-12-25T16:07:59.925212","exception":false,"start_time":"2021-12-25T16:07:59.832252","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:47:44.792116Z","iopub.execute_input":"2021-12-26T08:47:44.792433Z","iopub.status.idle":"2021-12-26T08:47:44.840885Z","shell.execute_reply.started":"2021-12-26T08:47:44.792402Z","shell.execute_reply":"2021-12-26T08:47:44.840044Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Inference:** The stats seem to be fine, let us do further analysis on the Dataset","metadata":{"papermill":{"duration":0.059885,"end_time":"2021-12-25T16:08:00.044925","exception":false,"start_time":"2021-12-25T16:07:59.98504","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.059004,"end_time":"2021-12-25T16:08:00.163017","exception":false,"start_time":"2021-12-25T16:08:00.104013","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <center> 2. Exploratory Data Analysis (EDA)","metadata":{"papermill":{"duration":0.059045,"end_time":"2021-12-25T16:08:00.281867","exception":false,"start_time":"2021-12-25T16:08:00.222822","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Let us first analyze the distribution of the target variable\n\nplt.figure(figsize=[8,4])\nsns.distplot(df[target], color='g',hist_kws=dict(edgecolor=\"black\", linewidth=2), bins=30)\nplt.title('Target Variable Distribution - Median Value of Homes ($1Ms)')\nplt.show()","metadata":{"papermill":{"duration":0.36649,"end_time":"2021-12-25T16:08:00.707843","exception":false,"start_time":"2021-12-25T16:08:00.341353","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:47:44.842038Z","iopub.execute_input":"2021-12-26T08:47:44.842727Z","iopub.status.idle":"2021-12-26T08:47:45.218169Z","shell.execute_reply.started":"2021-12-26T08:47:44.84268Z","shell.execute_reply":"2021-12-26T08:47:45.217455Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Inference:**The Target Variable seems to be be normally distributed, averaging around 20 units.","metadata":{"papermill":{"duration":0.057886,"end_time":"2021-12-25T16:08:00.824751","exception":false,"start_time":"2021-12-25T16:08:00.766865","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Visualising the categorical features \n\nprint('\\033[1mVisualising Categorical Features:'.center(100))\n\nn=2\nplt.figure(figsize=[15,3*math.ceil(len(cf)/n)])\n\nfor i in range(len(cf)):\n    if df[cf[i]].nunique()<=8:\n        plt.subplot(math.ceil(len(cf)/n),n,i+1)\n        sns.countplot(df[cf[i]])\n    else:\n        plt.subplot(3,1,i-1)\n        sns.countplot(df[cf[i]])\n        \nplt.tight_layout()\nplt.show()","metadata":{"papermill":{"duration":0.53288,"end_time":"2021-12-25T16:08:01.416698","exception":false,"start_time":"2021-12-25T16:08:00.883818","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:47:45.219405Z","iopub.execute_input":"2021-12-26T08:47:45.220303Z","iopub.status.idle":"2021-12-26T08:47:46.731251Z","shell.execute_reply.started":"2021-12-26T08:47:45.220267Z","shell.execute_reply":"2021-12-26T08:47:46.730208Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Inference:** There are no categorical features in the dataset.","metadata":{"papermill":{"duration":0.061097,"end_time":"2021-12-25T16:08:01.539026","exception":false,"start_time":"2021-12-25T16:08:01.477929","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Visualising the numeric features \n\nprint('\\033[1mNumeric Features Distribution'.center(130))\n\nn=4\n\nclr=['r','g','b','g','b','r']\n\nplt.figure(figsize=[15,6*math.ceil(len(nf)/n)])\nfor i in range(len(nf)):\n    plt.subplot(math.ceil(len(nf)/3),n,i+1)\n    sns.distplot(df[nf[i]],hist_kws=dict(edgecolor=\"black\", linewidth=2), bins=10, color=list(np.random.randint([255,255,255])/255))\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=[15,6*math.ceil(len(nf)/n)])\nfor i in range(len(nf)):\n    plt.subplot(math.ceil(len(nf)/3),n,i+1)\n    df.boxplot(nf[i])\nplt.tight_layout()\nplt.show()","metadata":{"papermill":{"duration":1.544031,"end_time":"2021-12-25T16:08:03.144923","exception":false,"start_time":"2021-12-25T16:08:01.600892","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:47:46.732891Z","iopub.execute_input":"2021-12-26T08:47:46.733112Z","iopub.status.idle":"2021-12-26T08:47:48.405791Z","shell.execute_reply.started":"2021-12-26T08:47:46.733083Z","shell.execute_reply":"2021-12-26T08:47:48.404769Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Inference:** There seem to be some outliers. let us fix these in the upcoming section...","metadata":{"papermill":{"duration":0.064723,"end_time":"2021-12-25T16:08:03.274622","exception":false,"start_time":"2021-12-25T16:08:03.209899","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Understanding the relationship between all the features\n\ng = sns.pairplot(df)\nplt.title('Pairplots for all the Feature')\ng.map_upper(sns.kdeplot, levels=4, color=\".2\")\nplt.show()","metadata":{"papermill":{"duration":18.538322,"end_time":"2021-12-25T16:08:21.876533","exception":false,"start_time":"2021-12-25T16:08:03.338211","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:47:48.407011Z","iopub.execute_input":"2021-12-26T08:47:48.407548Z","iopub.status.idle":"2021-12-26T08:51:04.782422Z","shell.execute_reply.started":"2021-12-26T08:47:48.407515Z","shell.execute_reply":"2021-12-26T08:51:04.779877Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Inference:** We can notice that some features have linear relationship, let us futher analyze the detect multicollinearity.","metadata":{"papermill":{"duration":0.085111,"end_time":"2021-12-25T16:08:22.04918","exception":false,"start_time":"2021-12-25T16:08:21.964069","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.085688,"end_time":"2021-12-25T16:08:22.219206","exception":false,"start_time":"2021-12-25T16:08:22.133518","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <center> 3. Data Preprocessing","metadata":{"papermill":{"duration":0.085806,"end_time":"2021-12-25T16:08:22.390792","exception":false,"start_time":"2021-12-25T16:08:22.304986","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Removal of any Duplicate rows (if any)\n\ncounter = 0\nrs,cs = original_df.shape\n\ndf.drop_duplicates(inplace=True)\n\nif df.shape==(rs,cs):\n    print('\\n\\033[1mInference:\\033[0m The dataset doesn\\'t have any duplicates')\nelse:\n    print(f'\\n\\033[1mInference:\\033[0m Number of duplicates dropped/fixed ---> {rs-df.shape[0]}')","metadata":{"papermill":{"duration":0.096907,"end_time":"2021-12-25T16:08:22.572248","exception":false,"start_time":"2021-12-25T16:08:22.475341","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:51:04.784533Z","iopub.execute_input":"2021-12-26T08:51:04.784861Z","iopub.status.idle":"2021-12-26T08:51:04.799578Z","shell.execute_reply.started":"2021-12-26T08:51:04.78482Z","shell.execute_reply":"2021-12-26T08:51:04.798482Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Check for empty elements\n\nnvc = pd.DataFrame(df.isnull().sum().sort_values(), columns=['Total Null Values'])\nnvc['Percentage'] = round(nvc['Total Null Values']/df.shape[0],3)*100\nprint(nvc)","metadata":{"papermill":{"duration":0.097666,"end_time":"2021-12-25T16:08:22.757567","exception":false,"start_time":"2021-12-25T16:08:22.659901","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:51:04.804617Z","iopub.execute_input":"2021-12-26T08:51:04.804925Z","iopub.status.idle":"2021-12-26T08:51:04.818474Z","shell.execute_reply.started":"2021-12-26T08:51:04.804891Z","shell.execute_reply":"2021-12-26T08:51:04.817333Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Inference:** The datset doesn't have any inconsistant values.","metadata":{"papermill":{"duration":0.08433,"end_time":"2021-12-25T16:08:22.927809","exception":false,"start_time":"2021-12-25T16:08:22.843479","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Converting categorical Columns to Numeric\n\ndf3 = df.copy()\n\necc = nvc[nvc['Percentage']!=0].index.values\nfcc = [i for i in cf if i not in ecc]\n#One-Hot Binay Encoding\noh=True\ndm=True\nfor i in fcc:\n    #print(i)\n    if df3[i].nunique()==2:\n        if oh==True: print(\"\\033[1mOne-Hot Encoding on features:\\033[0m\")\n        print(i);oh=False\n        df3[i]=pd.get_dummies(df3[i], drop_first=True, prefix=str(i))\n    if (df3[i].nunique()>2):\n        if dm==True: print(\"\\n\\033[1mDummy Encoding on features:\\033[0m\")\n        print(i);dm=False\n        df3 = pd.concat([df3.drop([i], axis=1), pd.DataFrame(pd.get_dummies(df3[i], drop_first=True, prefix=str(i)))],axis=1)\n        \ndf3.shape","metadata":{"papermill":{"duration":0.113165,"end_time":"2021-12-25T16:08:23.124193","exception":false,"start_time":"2021-12-25T16:08:23.011028","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:51:04.820125Z","iopub.execute_input":"2021-12-26T08:51:04.820983Z","iopub.status.idle":"2021-12-26T08:51:04.85976Z","shell.execute_reply.started":"2021-12-26T08:51:04.820948Z","shell.execute_reply":"2021-12-26T08:51:04.85861Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for x in [i for i in ecc if i in cf]:\n#     a = df3[x]\n#     b=[]; c=[]\n\n#     df4 = df3.copy()\n#     df4.drop(ecc, axis=1, inplace=True)\n#     df4\n\n#     for i,e in enumerate(a):\n#         if e!=e:\n#             b.append(i)\n#         else:\n#             c.append(i)\n\n#     RF = RandomForestClassifier()\n#     RF.fit(df4.loc[c],a[c])\n#     d = RF.predict(df4.loc[b])\n\n#     f=0\n#     for i,e in enumerate(df3[x]):\n#         if e!=e:\n#             df3.loc[i,x] = d[f]\n#             f+=1\n# df1 = df3.copy()\n# df1","metadata":{"papermill":{"duration":0.093608,"end_time":"2021-12-25T16:08:23.304992","exception":false,"start_time":"2021-12-25T16:08:23.211384","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:51:04.861718Z","iopub.execute_input":"2021-12-26T08:51:04.862577Z","iopub.status.idle":"2021-12-26T08:51:04.868489Z","shell.execute_reply.started":"2021-12-26T08:51:04.862525Z","shell.execute_reply":"2021-12-26T08:51:04.867507Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #Converting categorical Columns to Numeric\n\n# df3 = df.copy()\n\n# gcc = nvc[nvc['Percentage']!=0].index.values\n# hcc = [i for i in cf if i not in gcc]\n\n# #One-Hot Binay Encoding\n# oh=True\n# dm=True\n# for i in hcc:\n#     #print(i)\n#     if df3[i].nunique()==2:\n#         if oh==True: print(\"\\033[1mOne-Hot Encoding on features:\\033[0m\")\n#         print(i);oh=False\n#         df3[i]=pd.get_dummies(df3[i], drop_first=True, prefix=str(i))\n#     if (df3[i].nunique()>2 and df3[i].nunique()<17):\n#         if dm==True: print(\"\\n\\033[1mDummy Encoding on features:\\033[0m\")\n#         print(i);dm=False\n#         df3 = pd.concat([df3.drop([i], axis=1), pd.DataFrame(pd.get_dummies(df3[i], drop_first=True, prefix=str(i)))],axis=1)\n# df3.shape","metadata":{"papermill":{"duration":0.095526,"end_time":"2021-12-25T16:08:23.487566","exception":false,"start_time":"2021-12-25T16:08:23.39204","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:51:04.869699Z","iopub.execute_input":"2021-12-26T08:51:04.870557Z","iopub.status.idle":"2021-12-26T08:51:04.885851Z","shell.execute_reply.started":"2021-12-26T08:51:04.870521Z","shell.execute_reply":"2021-12-26T08:51:04.884943Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for x in gcc:\n#     a = df3[x]\n#     b=[]; c=[]\n\n#     df4 = df3.copy()\n#     df4.drop([x], axis=1, inplace=True)\n    \n#     for i,e in enumerate(a):\n#         if e!=e:\n#             b.append(i)\n#         else:\n#             c.append(i)\n        \n#     LR = LinearRegression()\n#     LR.fit(df4.loc[c],a[c])\n#     d = LR.predict(df4.loc[b])\n        \n#     f=0\n#     for i,e in enumerate(df3[x]):\n#         if e!=e:\n#             df3.loc[i,x] = d[f]\n#             f+=1\n# df3","metadata":{"papermill":{"duration":0.094273,"end_time":"2021-12-25T16:08:23.669014","exception":false,"start_time":"2021-12-25T16:08:23.574741","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:51:04.88713Z","iopub.execute_input":"2021-12-26T08:51:04.887585Z","iopub.status.idle":"2021-12-26T08:51:04.898387Z","shell.execute_reply.started":"2021-12-26T08:51:04.887551Z","shell.execute_reply":"2021-12-26T08:51:04.897475Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Removal of outlier:\n\ndf1 = df3.copy()\n\n#features1 = [i for i in features if i not in ['CHAS','RAD']]\nfeatures1 = nf\n\nfor i in features1:\n    Q1 = df1[i].quantile(0.25)\n    Q3 = df1[i].quantile(0.75)\n    IQR = Q3 - Q1\n    df1 = df1[df1[i] <= (Q3+(1.5*IQR))]\n    df1 = df1[df1[i] >= (Q1-(1.5*IQR))]\n    df1 = df1.reset_index(drop=True)\ndisplay(df1.head())\nprint('\\n\\033[1mInference:\\033[0m\\nBefore removal of outliers, The dataset had {} samples.'.format(df3.shape[0]))\nprint('After removal of outliers, The dataset now has {} samples.'.format(df1.shape[0]))","metadata":{"papermill":{"duration":0.131585,"end_time":"2021-12-25T16:08:23.887598","exception":false,"start_time":"2021-12-25T16:08:23.756013","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:51:04.899841Z","iopub.execute_input":"2021-12-26T08:51:04.900278Z","iopub.status.idle":"2021-12-26T08:51:04.954306Z","shell.execute_reply.started":"2021-12-26T08:51:04.900247Z","shell.execute_reply":"2021-12-26T08:51:04.953035Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Final Dataset size after performing Preprocessing\n\ndf = df1.copy()\ndf.columns=[i.replace('-','_') for i in df.columns]\n\nplt.title('Final Dataset')\nplt.pie([df.shape[0], original_df.shape[0]-df.shape[0]], radius = 1, labels=['Retained','Dropped'], counterclock=False, \n        autopct='%1.1f%%', pctdistance=0.9, explode=[0,0], shadow=True)\nplt.pie([df.shape[0]], labels=['100%'], labeldistance=-0, radius=0.78)\nplt.show()\n\nprint(f'\\n\\033[1mInference:\\033[0m After the cleanup process, {original_df.shape[0]-df.shape[0]} samples were dropped, \\\nwhile retaining {round(100 - (df.shape[0]*100/(original_df.shape[0])),2)}% of the data.')","metadata":{"papermill":{"duration":0.233283,"end_time":"2021-12-25T16:08:24.210205","exception":false,"start_time":"2021-12-25T16:08:23.976922","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:51:04.955878Z","iopub.execute_input":"2021-12-26T08:51:04.956598Z","iopub.status.idle":"2021-12-26T08:51:05.148255Z","shell.execute_reply.started":"2021-12-26T08:51:04.956544Z","shell.execute_reply":"2021-12-26T08:51:05.147241Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.089703,"end_time":"2021-12-25T16:08:24.389811","exception":false,"start_time":"2021-12-25T16:08:24.300108","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <center> 4. Data Manipulation","metadata":{"papermill":{"duration":0.093426,"end_time":"2021-12-25T16:08:24.5731","exception":false,"start_time":"2021-12-25T16:08:24.479674","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Splitting the data intro training & testing sets\n\nm=[]\nfor i in df.columns.values:\n    m.append(i.replace(' ','_'))\n    \ndf.columns = m\nX = df.drop([target],axis=1)\nY = df[target]\nTrain_X, Test_X, Train_Y, Test_Y = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=100)\nTrain_X.reset_index(drop=True,inplace=True)\n\nprint('Original set  ---> ',X.shape,Y.shape,'\\nTraining set  ---> ',Train_X.shape,Train_Y.shape,'\\nTesting set   ---> ', Test_X.shape,'', Test_Y.shape)","metadata":{"papermill":{"duration":0.103774,"end_time":"2021-12-25T16:08:24.767063","exception":false,"start_time":"2021-12-25T16:08:24.663289","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:51:05.149668Z","iopub.execute_input":"2021-12-26T08:51:05.150308Z","iopub.status.idle":"2021-12-26T08:51:05.166836Z","shell.execute_reply.started":"2021-12-26T08:51:05.150274Z","shell.execute_reply":"2021-12-26T08:51:05.16612Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Feature Scaling (Standardization)\n\nstd = StandardScaler()\n\nprint('\\033[1mStandardardization on Training set'.center(120))\nTrain_X_std = std.fit_transform(Train_X)\nTrain_X_std = pd.DataFrame(Train_X_std, columns=X.columns)\ndisplay(Train_X_std.describe())\n\nprint('\\n','\\033[1mStandardardization on Testing set'.center(120))\nTest_X_std = std.transform(Test_X)\nTest_X_std = pd.DataFrame(Test_X_std, columns=X.columns)\ndisplay(Test_X_std.describe())","metadata":{"papermill":{"duration":0.228791,"end_time":"2021-12-25T16:08:25.082675","exception":false,"start_time":"2021-12-25T16:08:24.853884","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:51:05.168133Z","iopub.execute_input":"2021-12-26T08:51:05.16858Z","iopub.status.idle":"2021-12-26T08:51:05.554733Z","shell.execute_reply.started":"2021-12-26T08:51:05.168543Z","shell.execute_reply":"2021-12-26T08:51:05.553623Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.091133,"end_time":"2021-12-25T16:08:25.264173","exception":false,"start_time":"2021-12-25T16:08:25.17304","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <center> 5. Feature Selection/Extraction","metadata":{"papermill":{"duration":0.090467,"end_time":"2021-12-25T16:08:25.444331","exception":false,"start_time":"2021-12-25T16:08:25.353864","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Checking the correlation\n\nprint('\\033[1mCorrelation Matrix'.center(100))\nplt.figure(figsize=[25,20])\nsns.heatmap(df.corr(), annot=True, vmin=-1, vmax=1, center=0) #cmap='BuGn'\nplt.show()","metadata":{"papermill":{"duration":2.802762,"end_time":"2021-12-25T16:08:28.341011","exception":false,"start_time":"2021-12-25T16:08:25.538249","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:51:05.556486Z","iopub.execute_input":"2021-12-26T08:51:05.556835Z","iopub.status.idle":"2021-12-26T08:51:29.839396Z","shell.execute_reply.started":"2021-12-26T08:51:05.556772Z","shell.execute_reply":"2021-12-26T08:51:29.838419Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Inference:** There seems to be strong multi-correlation between the features. Let us try to fix these...","metadata":{"papermill":{"duration":0.102497,"end_time":"2021-12-25T16:08:28.544899","exception":false,"start_time":"2021-12-25T16:08:28.442402","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Testing a Linear Regression model with statsmodels\n\nTrain_xy = pd.concat([Train_X_std,Train_Y.reset_index(drop=True)],axis=1)\na = Train_xy.columns.values\n\nAPI = api.ols(formula='{} ~ {}'.format(target,' + '.join(i for i in Train_X.columns)), data=Train_xy).fit()\n#print(API.conf_int())\n#print(API.pvalues)\nAPI.summary()","metadata":{"papermill":{"duration":0.168162,"end_time":"2021-12-25T16:08:28.812836","exception":false,"start_time":"2021-12-25T16:08:28.644674","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:51:29.841043Z","iopub.execute_input":"2021-12-26T08:51:29.841736Z","iopub.status.idle":"2021-12-26T08:51:30.114012Z","shell.execute_reply.started":"2021-12-26T08:51:29.841695Z","shell.execute_reply":"2021-12-26T08:51:30.112983Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" ---","metadata":{"papermill":{"duration":0.109185,"end_time":"2021-12-25T16:08:29.031928","exception":false,"start_time":"2021-12-25T16:08:28.922743","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**Approach:** \nWe can fix these multicollinearity with two techniques:\n1. Manual Method - Variance Inflation Factor (VIF)\n2. Automatic Method - Recursive Feature Elimination (RFE)\n3. Feature Elmination using PCA Decomposition","metadata":{"papermill":{"duration":0.0982,"end_time":"2021-12-25T16:08:29.230936","exception":false,"start_time":"2021-12-25T16:08:29.132736","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 5a. Manual Method - VIF","metadata":{"papermill":{"duration":0.096053,"end_time":"2021-12-25T16:08:29.425789","exception":false,"start_time":"2021-12-25T16:08:29.329736","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nTrr=[]; Tss=[]; n=3\norder=['ord-'+str(i) for i in range(2,n)]\n#Trd = pd.DataFrame(np.zeros((10,n-2)), columns=order)\n#Tsd = pd.DataFrame(np.zeros((10,n-2)), columns=order)\n\nDROP=[];b=[]\n\nfor i in range(len(Train_X_std.columns)):\n    vif = pd.DataFrame()\n    X = Train_X_std.drop(DROP,axis=1)\n    vif['Features'] = X.columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    vif.reset_index(drop=True, inplace=True)\n    if vif.loc[0][1]>1:\n        DROP.append(vif.loc[0][0])\n        LR = LinearRegression()\n        LR.fit(Train_X_std.drop(DROP,axis=1), Train_Y)\n\n        pred1 = LR.predict(Train_X_std.drop(DROP,axis=1))\n        pred2 = LR.predict(Test_X_std.drop(DROP,axis=1))\n        \n        Trr.append(np.sqrt(mean_squared_error(Train_Y, pred1)))\n        Tss.append(np.sqrt(mean_squared_error(Test_Y, pred2)))\n\n        #Trd.loc[i,'ord-'+str(k)] = round(np.sqrt(mean_squared_error(Train_Y, pred1)),2)\n        #Tsd.loc[i,'ord-'+str(k)] = round(np.sqrt(mean_squared_error(Test_Y, pred2)),2)\n        \nprint('Dropped Features --> ',DROP)\n#plt.plot(b)\n#plt.show()\n#print(API.summary())\n\n# plt.figure(figsize=[20,4])\n# plt.subplot(1,3,1)\n# sns.heatmap(Trd.loc[:6], cmap='BuGn', annot=True, vmin=0, vmax=Trd.max().max())\n# plt.title('Train RMSE')\n# plt.subplot(1,3,2)\n# sns.heatmap(Tsd.loc[:6], cmap='BuGn', annot=True, vmin=0, vmax=Trd.max().max()+10)\n# plt.title('Test RMSE')\n# plt.subplot(1,3,3)\n# sns.heatmap((Trd+Tsd).loc[:6], cmap='BuGn', annot=True, vmin=0, vmax=Trd.max().max()+25)\n# plt.title('Total RMSE')\n# plt.show()\n\nplt.plot(Trr, label='Train RMSE')\nplt.plot(Tss, label='Test RMSE')\n#plt.ylim([19.75,20.75])\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"papermill":{"duration":0.763298,"end_time":"2021-12-25T16:08:30.285992","exception":false,"start_time":"2021-12-25T16:08:29.522694","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:51:30.115883Z","iopub.execute_input":"2021-12-26T08:51:30.116516Z","iopub.status.idle":"2021-12-26T08:52:42.993277Z","shell.execute_reply.started":"2021-12-26T08:51:30.116462Z","shell.execute_reply":"2021-12-26T08:52:42.992132Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5b. Automatic Method - RFE","metadata":{"papermill":{"duration":0.103364,"end_time":"2021-12-25T16:08:30.493188","exception":false,"start_time":"2021-12-25T16:08:30.389824","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nTrr=[]; Tss=[]; n=3\norder=['ord-'+str(i) for i in range(2,n)]\nTrd = pd.DataFrame(np.zeros((10,n-2)), columns=order)\nTsd = pd.DataFrame(np.zeros((10,n-2)), columns=order)\n\nm=df.shape[1]-2\nfor i in range(m):\n    lm = LinearRegression()\n    rfe = RFE(lm,n_features_to_select=Train_X_std.shape[1]-i)             # running RFE\n    rfe = rfe.fit(Train_X_std, Train_Y)\n\n    LR = LinearRegression()\n    LR.fit(Train_X_std.loc[:,rfe.support_], Train_Y)\n\n    pred1 = LR.predict(Train_X_std.loc[:,rfe.support_])\n    pred2 = LR.predict(Test_X_std.loc[:,rfe.support_])\n\n    Trr.append(np.sqrt(mean_squared_error(Train_Y, pred1)))\n    Tss.append(np.sqrt(mean_squared_error(Test_Y, pred2)))\n\n# plt.figure(figsize=[20,4])\n# plt.subplot(1,3,1)\n# sns.heatmap(Trd.loc[:6], cmap='BuGn', annot=True, vmin=0, vmax=Trd.max().max())\n# plt.title('Train RMSE')\n# plt.subplot(1,3,2)\n# sns.heatmap(Tsd.loc[:6], cmap='BuGn', annot=True, vmin=0, vmax=Trd.max().max()+10)\n# plt.title('Test RMSE')\n# plt.subplot(1,3,3)\n# sns.heatmap((Trd+Tsd).loc[:6], cmap='BuGn', annot=True, vmin=0, vmax=Trd.max().max()+25)\n# plt.title('Total RMSE')\n# plt.show()\n\nplt.plot(Trr, label='Train RMSE')\nplt.plot(Tss, label='Test RMSE')\n#plt.ylim([19.75,20.75])\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"papermill":{"duration":0.682129,"end_time":"2021-12-25T16:08:31.279328","exception":false,"start_time":"2021-12-25T16:08:30.597199","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:52:42.995312Z","iopub.execute_input":"2021-12-26T08:52:42.995784Z","iopub.status.idle":"2021-12-26T08:53:12.771021Z","shell.execute_reply.started":"2021-12-26T08:52:42.995692Z","shell.execute_reply":"2021-12-26T08:53:12.769579Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5c. Feature Elmination using PCA Decomposition","metadata":{"papermill":{"duration":0.100171,"end_time":"2021-12-25T16:08:31.478031","exception":false,"start_time":"2021-12-25T16:08:31.37786","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA().fit(Train_X_std)\n\nfig, ax = plt.subplots(figsize=(8,6))\nx_values = range(1, pca.n_components_+1)\nax.bar(x_values, pca.explained_variance_ratio_, lw=2, label='Explained Variance')\nax.plot(x_values, np.cumsum(pca.explained_variance_ratio_), lw=2, label='Cumulative Explained Variance', color='red')\nplt.plot([0,pca.n_components_+1],[0.9,0.9],'g--')\nax.set_title('Explained variance of components')\nax.set_xlabel('Principal Component')\nax.set_ylabel('Explained Variance')\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"papermill":{"duration":0.370884,"end_time":"2021-12-25T16:08:31.949824","exception":false,"start_time":"2021-12-25T16:08:31.57894","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:53:12.77434Z","iopub.execute_input":"2021-12-26T08:53:12.77575Z","iopub.status.idle":"2021-12-26T08:53:13.48032Z","shell.execute_reply.started":"2021-12-26T08:53:12.775692Z","shell.execute_reply":"2021-12-26T08:53:13.478993Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import PolynomialFeatures\nTrr=[]; Tss=[]; n=3\norder=['ord-'+str(i) for i in range(2,n)]\nTrd = pd.DataFrame(np.zeros((10,n-2)), columns=order)\nTsd = pd.DataFrame(np.zeros((10,n-2)), columns=order)\nm=df.shape[1]-1\n\nfor i in range(m):\n    pca = PCA(n_components=Train_X_std.shape[1]-i)\n    Train_X_std_pca = pca.fit_transform(Train_X_std)\n    Test_X_std_pca = pca.fit_transform(Test_X_std)\n    \n    LR = LinearRegression()\n    LR.fit(Train_X_std_pca, Train_Y)\n\n    pred1 = LR.predict(Train_X_std_pca)\n    pred2 = LR.predict(Test_X_std_pca)\n\n    Trr.append(round(np.sqrt(mean_squared_error(Train_Y, pred1)),2))\n    Tss.append(round(np.sqrt(mean_squared_error(Test_Y, pred2)),2))\n\n# plt.figure(figsize=[20,4.5])\n# plt.subplot(1,3,1)\n# sns.heatmap(Trd.loc[:6], cmap='BuGn', annot=True, vmin=0, vmax=Trd.max().max())\n# plt.title('Train RMSE')\n# plt.subplot(1,3,2)\n# sns.heatmap(Tsd.loc[:6], cmap='BuGn', annot=True, vmin=0, vmax=Trd.max().max()+10)\n# plt.title('Test RMSE')\n# plt.subplot(1,3,3)\n# sns.heatmap((Trd+Tsd).loc[:6], cmap='BuGn', annot=True, vmin=0, vmax=Trd.max().max()+25)\n# plt.title('Total RMSE')\n# plt.show()\n\nplt.plot(Trr, label='Train RMSE')\nplt.plot(Tss, label='Test RMSE')\n#plt.ylim([19.5,20.75])\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"papermill":{"duration":0.430641,"end_time":"2021-12-25T16:08:32.482592","exception":false,"start_time":"2021-12-25T16:08:32.051951","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:53:13.482598Z","iopub.execute_input":"2021-12-26T08:53:13.482916Z","iopub.status.idle":"2021-12-26T08:53:20.579074Z","shell.execute_reply.started":"2021-12-26T08:53:13.48286Z","shell.execute_reply":"2021-12-26T08:53:20.578349Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Inference:\nIt can be seen that the performance of the modelsis quiet comparable unpon dropping features using VIF, RFE & PCA Techniques. Comparing the RMSE plots, the optimal values were found for dropping most  features using manual RFE Technique. But let us skip these for now, as the advanced ML Algorithms take care of multicollinearity.","metadata":{"papermill":{"duration":0.107597,"end_time":"2021-12-25T16:08:32.697898","exception":false,"start_time":"2021-12-25T16:08:32.590301","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Shortlisting the selected Features (with RFE)\n\nlm = LinearRegression()\nrfe = RFE(lm,n_features_to_select=Train_X_std.shape[1]-28)             # running RFE\nrfe = rfe.fit(Train_X_std, Train_Y)\n\nLR = LinearRegression()\nLR.fit(Train_X_std.loc[:,rfe.support_], Train_Y)\n\n#print(Train_X_std.loc[:,rfe.support_].columns)\n\npred1 = LR.predict(Train_X_std.loc[:,rfe.support_])\npred2 = LR.predict(Test_X_std.loc[:,rfe.support_])\n\nprint(np.sqrt(mean_squared_error(Train_Y, pred1)))\nprint(np.sqrt(mean_squared_error(Test_Y, pred2)))\n\nTrain_X_std = Train_X_std.loc[:,rfe.support_]\nTest_X_std = Test_X_std.loc[:,rfe.support_]","metadata":{"papermill":{"duration":0.109394,"end_time":"2021-12-25T16:08:32.912324","exception":false,"start_time":"2021-12-25T16:08:32.80293","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:53:20.580156Z","iopub.execute_input":"2021-12-26T08:53:20.580509Z","iopub.status.idle":"2021-12-26T08:53:21.006992Z","shell.execute_reply.started":"2021-12-26T08:53:20.580479Z","shell.execute_reply":"2021-12-26T08:53:21.005892Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.104296,"end_time":"2021-12-25T16:08:33.120243","exception":false,"start_time":"2021-12-25T16:08:33.015947","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <center> 6. Predictive Modelling","metadata":{"papermill":{"duration":0.10223,"end_time":"2021-12-25T16:08:33.32786","exception":false,"start_time":"2021-12-25T16:08:33.22563","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Let us first define a function to evaluate our models\n\nModel_Evaluation_Comparison_Matrix = pd.DataFrame(np.zeros([5,8]), columns=['Train-R2','Test-R2','Train-RSS','Test-RSS',\n                                                                            'Train-MSE','Test-MSE','Train-RMSE','Test-RMSE'])\nrc=np.random.choice(Train_X_std.loc[:,Train_X_std.nunique()>=50].columns.values,2,replace=False)\ndef Evaluate(n, pred1,pred2):\n    #Plotting predicted predicteds alongside the actual datapoints \n    plt.figure(figsize=[15,6])\n    for e,i in enumerate(rc):\n        plt.subplot(2,3,e+1)\n        plt.scatter(y=Train_Y, x=Train_X_std[i], label='Actual')\n        plt.scatter(y=pred1, x=Train_X_std[i], label='Prediction')\n        plt.legend()\n    plt.show()\n\n    #Evaluating the Multiple Linear Regression Model\n\n    print('\\n\\n{}Training Set Metrics{}'.format('-'*20, '-'*20))\n    print('\\nR2-Score on Training set --->',round(r2_score(Train_Y, pred1),20))\n    print('Residual Sum of Squares (RSS) on Training set  --->',round(np.sum(np.square(Train_Y-pred1)),20))\n    print('Mean Squared Error (MSE) on Training set       --->',round(mean_squared_error(Train_Y, pred1),20))\n    print('Root Mean Squared Error (RMSE) on Training set --->',round(np.sqrt(mean_squared_error(Train_Y, pred1)),20))\n\n    print('\\n{}Testing Set Metrics{}'.format('-'*20, '-'*20))\n    print('\\nR2-Score on Testing set --->',round(r2_score(Test_Y, pred2),20))\n    print('Residual Sum of Squares (RSS) on Training set  --->',round(np.sum(np.square(Test_Y-pred2)),20))\n    print('Mean Squared Error (MSE) on Training set       --->',round(mean_squared_error(Test_Y, pred2),20))\n    print('Root Mean Squared Error (RMSE) on Training set --->',round(np.sqrt(mean_squared_error(Test_Y, pred2)),20))\n    print('\\n{}Residual Plots{}'.format('-'*20, '-'*20))\n    \n    Model_Evaluation_Comparison_Matrix.loc[n,'Train-R2']  = round(r2_score(Train_Y, pred1),20)\n    Model_Evaluation_Comparison_Matrix.loc[n,'Test-R2']   = round(r2_score(Test_Y, pred2),20)\n    Model_Evaluation_Comparison_Matrix.loc[n,'Train-RSS'] = round(np.sum(np.square(Train_Y-pred1)),20)\n    Model_Evaluation_Comparison_Matrix.loc[n,'Test-RSS']  = round(np.sum(np.square(Test_Y-pred2)),20)\n    Model_Evaluation_Comparison_Matrix.loc[n,'Train-MSE'] = round(mean_squared_error(Train_Y, pred1),20)\n    Model_Evaluation_Comparison_Matrix.loc[n,'Test-MSE']  = round(mean_squared_error(Test_Y, pred2),20)\n    Model_Evaluation_Comparison_Matrix.loc[n,'Train-RMSE']= round(np.sqrt(mean_squared_error(Train_Y, pred1)),20)\n    Model_Evaluation_Comparison_Matrix.loc[n,'Test-RMSE'] = round(np.sqrt(mean_squared_error(Test_Y, pred2)),20)\n\n    # Plotting y_test and y_pred to understand the spread.\n    plt.figure(figsize=[15,4])\n\n    plt.subplot(1,2,1)\n    sns.distplot((Train_Y - pred1))\n    plt.title('Error Terms')          \n    plt.xlabel('Errors') \n\n    plt.subplot(1,2,2)\n    plt.scatter(Train_Y,pred1)\n    plt.plot([Train_Y.min(),Train_Y.max()],[Train_Y.min(),Train_Y.max()], 'r--')\n    plt.title('Test vs Prediction')         \n    plt.xlabel('y_test')                       \n    plt.ylabel('y_pred')                       \n    plt.show()","metadata":{"papermill":{"duration":0.134133,"end_time":"2021-12-25T16:08:33.565332","exception":false,"start_time":"2021-12-25T16:08:33.431199","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:53:21.008993Z","iopub.execute_input":"2021-12-26T08:53:21.00959Z","iopub.status.idle":"2021-12-26T08:53:21.068749Z","shell.execute_reply.started":"2021-12-26T08:53:21.009532Z","shell.execute_reply":"2021-12-26T08:53:21.067515Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.106523,"end_time":"2021-12-25T16:08:33.783157","exception":false,"start_time":"2021-12-25T16:08:33.676634","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Objective: \nLet us now try building multiple regression models & compare their evaluation metrics to choose the best fit model both training and testing sets...","metadata":{"papermill":{"duration":0.104021,"end_time":"2021-12-25T16:08:33.998728","exception":false,"start_time":"2021-12-25T16:08:33.894707","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 6a. Multiple Linear Regression(MLR)","metadata":{"papermill":{"duration":0.098499,"end_time":"2021-12-25T16:08:34.19876","exception":false,"start_time":"2021-12-25T16:08:34.100261","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/Masterx-AI/Master-AI/main/3.%20Machine%20Learning/Z-Etc/Reg/mr.png\" style=\"width: 600px;float: left;\"/>","metadata":{"papermill":{"duration":0.098386,"end_time":"2021-12-25T16:08:34.395216","exception":false,"start_time":"2021-12-25T16:08:34.29683","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Linear Regression\n\nMLR = LinearRegression().fit(Train_X_std,Train_Y)\npred1 = MLR.predict(Train_X_std)\npred2 = MLR.predict(Test_X_std)\n\nprint('{}{}\\033[1m Evaluating Multiple Linear Regression Model \\033[0m{}{}\\n'.format('<'*3,'-'*35 ,'-'*35,'>'*3))\n#print('The Coeffecient of the Regresion Model was found to be ',MLR.coef_)\nprint('The Intercept of the Regresion Model was found to be ',MLR.intercept_)\n\nEvaluate(0, pred1, pred2)","metadata":{"papermill":{"duration":0.852113,"end_time":"2021-12-25T16:08:35.350335","exception":false,"start_time":"2021-12-25T16:08:34.498222","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:53:21.071176Z","iopub.execute_input":"2021-12-26T08:53:21.071921Z","iopub.status.idle":"2021-12-26T08:53:22.886915Z","shell.execute_reply.started":"2021-12-26T08:53:21.071866Z","shell.execute_reply":"2021-12-26T08:53:22.885645Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.10624,"end_time":"2021-12-25T16:08:35.566604","exception":false,"start_time":"2021-12-25T16:08:35.460364","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 6b. Ridge Regression Model","metadata":{"papermill":{"duration":0.107976,"end_time":"2021-12-25T16:08:35.784952","exception":false,"start_time":"2021-12-25T16:08:35.676976","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/Masterx-AI/Master-AI/main/3.%20Machine%20Learning/Z-Etc/Reg/ridge.png\" style=\"width: 500px;float: left;\"/>","metadata":{"papermill":{"duration":0.109968,"end_time":"2021-12-25T16:08:36.003766","exception":false,"start_time":"2021-12-25T16:08:35.893798","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Creating a Ridge Regression model\n\nRLR = Ridge().fit(Train_X_std,Train_Y)\npred1 = RLR.predict(Train_X_std)\npred2 = RLR.predict(Test_X_std)\n\nprint('{}{}\\033[1m Evaluating Ridge Regression Model \\033[0m{}{}\\n'.format('<'*3,'-'*35 ,'-'*35,'>'*3))\n#print('The Coeffecient of the Regresion Model was found to be ',MLR.coef_)\nprint('The Intercept of the Regresion Model was found to be ',MLR.intercept_)\n\nEvaluate(1, pred1, pred2)","metadata":{"papermill":{"duration":0.870882,"end_time":"2021-12-25T16:08:36.982577","exception":false,"start_time":"2021-12-25T16:08:36.111695","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:53:22.888433Z","iopub.execute_input":"2021-12-26T08:53:22.888692Z","iopub.status.idle":"2021-12-26T08:53:24.78688Z","shell.execute_reply.started":"2021-12-26T08:53:22.888661Z","shell.execute_reply":"2021-12-26T08:53:24.785874Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.11511,"end_time":"2021-12-25T16:08:37.214679","exception":false,"start_time":"2021-12-25T16:08:37.099569","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 6c. Lasso Regression Model","metadata":{"papermill":{"duration":0.11024,"end_time":"2021-12-25T16:08:37.434074","exception":false,"start_time":"2021-12-25T16:08:37.323834","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/Masterx-AI/Master-AI/main/3.%20Machine%20Learning/Z-Etc/Reg/lasso.png\" style=\"width: 500px;float: left;\"/>","metadata":{"papermill":{"duration":0.113605,"end_time":"2021-12-25T16:08:37.659716","exception":false,"start_time":"2021-12-25T16:08:37.546111","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Creating a Ridge Regression model\n\nLLR = Lasso().fit(Train_X_std,Train_Y)\npred1 = LLR.predict(Train_X_std)\npred2 = LLR.predict(Test_X_std)\n\nprint('{}{}\\033[1m Evaluating Lasso Regression Model \\033[0m{}{}\\n'.format('<'*3,'-'*35 ,'-'*35,'>'*3))\n#print('The Coeffecient of the Regresion Model was found to be ',MLR.coef_)\nprint('The Intercept of the Regresion Model was found to be ',MLR.intercept_)\n\nEvaluate(2, pred1, pred2)","metadata":{"papermill":{"duration":0.861075,"end_time":"2021-12-25T16:08:38.631929","exception":false,"start_time":"2021-12-25T16:08:37.770854","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:53:24.788231Z","iopub.execute_input":"2021-12-26T08:53:24.78849Z","iopub.status.idle":"2021-12-26T08:53:27.40937Z","shell.execute_reply.started":"2021-12-26T08:53:24.788428Z","shell.execute_reply":"2021-12-26T08:53:27.408323Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.121822,"end_time":"2021-12-25T16:08:38.874113","exception":false,"start_time":"2021-12-25T16:08:38.752291","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 6d. Elastic-Net Regression","metadata":{"papermill":{"duration":0.113262,"end_time":"2021-12-25T16:08:39.102935","exception":false,"start_time":"2021-12-25T16:08:38.989673","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/Masterx-AI/Master-AI/main/3.%20Machine%20Learning/Z-Etc/Reg/en.png\" style=\"width: 500px;float: left;\"/>","metadata":{"papermill":{"duration":0.111359,"end_time":"2021-12-25T16:08:39.326198","exception":false,"start_time":"2021-12-25T16:08:39.214839","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Creating a ElasticNet Regression model\n\nENR = ElasticNet().fit(Train_X_std,Train_Y)\npred1 = ENR.predict(Train_X_std)\npred2 = ENR.predict(Test_X_std)\n\nprint('{}{}\\033[1m Evaluating Elastic-Net Regression Model \\033[0m{}{}\\n'.format('<'*3,'-'*35 ,'-'*35,'>'*3))\n#print('The Coeffecient of the Regresion Model was found to be ',MLR.coef_)\nprint('The Intercept of the Regresion Model was found to be ',MLR.intercept_)\n\nEvaluate(3, pred1, pred2)","metadata":{"papermill":{"duration":0.907759,"end_time":"2021-12-25T16:08:40.344486","exception":false,"start_time":"2021-12-25T16:08:39.436727","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:53:27.411009Z","iopub.execute_input":"2021-12-26T08:53:27.411969Z","iopub.status.idle":"2021-12-26T08:53:29.235481Z","shell.execute_reply.started":"2021-12-26T08:53:27.411927Z","shell.execute_reply":"2021-12-26T08:53:29.234382Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.119606,"end_time":"2021-12-25T16:08:40.585704","exception":false,"start_time":"2021-12-25T16:08:40.466098","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 6e. Polynomial Regression Model","metadata":{"papermill":{"duration":0.119887,"end_time":"2021-12-25T16:08:40.826554","exception":false,"start_time":"2021-12-25T16:08:40.706667","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/Masterx-AI/Master-AI/main/3.%20Machine%20Learning/Z-Etc/Reg/pn.png\" style=\"width: 500px;float: left;\"/>","metadata":{"papermill":{"duration":0.12069,"end_time":"2021-12-25T16:08:41.065499","exception":false,"start_time":"2021-12-25T16:08:40.944809","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Checking polynomial regression performance on various degrees\n\nTrr=[]; Tss=[]\nn_degree=4\n\nfor i in range(2,n_degree):\n    #print(f'{i} Degree')\n    poly_reg = PolynomialFeatures(degree=i)\n    X_poly = poly_reg.fit_transform(Train_X_std)\n    X_poly1 = poly_reg.fit_transform(Test_X_std)\n    LR = LinearRegression()\n    LR.fit(X_poly, Train_Y)\n    \n    pred1 = LR.predict(X_poly)\n    Trr.append(np.sqrt(mean_squared_error(Train_Y, pred1)))\n    \n    pred2 = LR.predict(X_poly1)\n    Tss.append(np.sqrt(mean_squared_error(Test_Y, pred2)))\n\nplt.figure(figsize=[15,6])\nplt.subplot(1,2,1)\nplt.plot(range(2,n_degree),Trr, label='Training')\nplt.plot(range(2,n_degree),Tss, label='Testing')\n#plt.plot([1,4],[1,4],'b--')\nplt.title('Polynomial Regression Fit')\n#plt.ylim([0,5])\nplt.xlabel('Degree')\nplt.ylabel('RMSE')\nplt.grid()\nplt.legend()\n#plt.xticks()\n\nplt.subplot(1,2,2)\nplt.plot(range(2,n_degree),Trr, label='Training')\nplt.plot(range(2,n_degree),Tss, label='Testing')\nplt.title('Polynomial Regression Fit')\nplt.ylim([0,2e16])\nplt.xlabel('Degree')\nplt.ylabel('RMSE')\nplt.grid()\nplt.legend()\n#plt.xticks()\nplt.show()","metadata":{"papermill":{"duration":29.127601,"end_time":"2021-12-25T16:09:10.312631","exception":false,"start_time":"2021-12-25T16:08:41.18503","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:53:29.237022Z","iopub.execute_input":"2021-12-26T08:53:29.23729Z","iopub.status.idle":"2021-12-26T08:54:23.194523Z","shell.execute_reply.started":"2021-12-26T08:53:29.237256Z","shell.execute_reply":"2021-12-26T08:54:23.193498Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Inference:** We can choose 2nd order polynomial regression as it gives the optimal training & testing scores...","metadata":{"papermill":{"duration":0.11992,"end_time":"2021-12-25T16:09:10.553033","exception":false,"start_time":"2021-12-25T16:09:10.433113","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Using the 2nd Order Polynomial Regression model (degree=2)\n\npoly_reg = PolynomialFeatures(degree=2)\nX_poly = poly_reg.fit_transform(Train_X_std)\nX_poly1 = poly_reg.fit_transform(Test_X_std)\nPR = LinearRegression()\nPR.fit(X_poly, Train_Y)\n\npred1 = PR.predict(X_poly)\npred2 = PR.predict(X_poly1)\n\nprint('{}{}\\033[1m Evaluating Polynomial Regression Model \\033[0m{}{}\\n'.format('<'*3,'-'*35 ,'-'*35,'>'*3))\nprint('The Coeffecient of the Regresion Model was found to be ',MLR.coef_)\nprint('The Intercept of the Regresion Model was found to be ',MLR.intercept_)\n\nEvaluate(4, pred1, pred2)","metadata":{"papermill":{"duration":4.546626,"end_time":"2021-12-25T16:09:15.219567","exception":false,"start_time":"2021-12-25T16:09:10.672941","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:54:23.195707Z","iopub.execute_input":"2021-12-26T08:54:23.195937Z","iopub.status.idle":"2021-12-26T08:54:25.579074Z","shell.execute_reply.started":"2021-12-26T08:54:23.195907Z","shell.execute_reply":"2021-12-26T08:54:25.57776Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.122936,"end_time":"2021-12-25T16:09:15.462279","exception":false,"start_time":"2021-12-25T16:09:15.339343","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### 6f. Comparing the Evaluation Metics of the Models","metadata":{"papermill":{"duration":0.123552,"end_time":"2021-12-25T16:09:15.708841","exception":false,"start_time":"2021-12-25T16:09:15.585289","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Regression Models Results Evaluation\n\nEMC = Model_Evaluation_Comparison_Matrix.copy()\nEMC.index = ['Multiple Linear Regression (MLR)','Ridge Linear Regression (RLR)','Lasso Linear Regression (LLR)','Elastic-Net Regression (ENR)','Polynomial Regression (PNR)']\nEMC","metadata":{"papermill":{"duration":0.168922,"end_time":"2021-12-25T16:09:15.998941","exception":false,"start_time":"2021-12-25T16:09:15.830019","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:54:25.581656Z","iopub.execute_input":"2021-12-26T08:54:25.582785Z","iopub.status.idle":"2021-12-26T08:54:25.604192Z","shell.execute_reply.started":"2021-12-26T08:54:25.582723Z","shell.execute_reply":"2021-12-26T08:54:25.603219Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# R2-Scores Comparison for different Regression Models\n\nR2 = round(EMC['Train-R2'].sort_values(ascending=True),4)\nplt.hlines(y=R2.index, xmin=0, xmax=R2.values)\nplt.plot(R2.values, R2.index,'o')\nplt.title('R2-Scores Comparison for various Regression Models')\nplt.xlabel('R2-Score')\n#plt.ylabel('Regression Models')\nfor i, v in enumerate(R2):\n    plt.text(v+0.02, i-0.05, str(v*100), color='blue')\nplt.xlim([0,1.1])\nplt.show()","metadata":{"papermill":{"duration":0.356241,"end_time":"2021-12-25T16:09:16.482999","exception":false,"start_time":"2021-12-25T16:09:16.126758","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:54:25.605479Z","iopub.execute_input":"2021-12-26T08:54:25.605721Z","iopub.status.idle":"2021-12-26T08:54:25.792309Z","shell.execute_reply.started":"2021-12-26T08:54:25.60569Z","shell.execute_reply":"2021-12-26T08:54:25.791215Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Inference:** From the above plot, it is clear that the polynomial regresion models have the highest explainability power  to understand the dataset.","metadata":{"papermill":{"duration":0.127716,"end_time":"2021-12-25T16:09:16.736771","exception":false,"start_time":"2021-12-25T16:09:16.609055","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Root Mean SquaredError Comparison for different Regression Models\n\ncc = Model_Evaluation_Comparison_Matrix.columns.values\ns=5\n\nplt.bar(np.arange(5), Model_Evaluation_Comparison_Matrix[cc[6]].values, width=0.3, label='RMSE (Training)')\nplt.bar(np.arange(5)+0.3, Model_Evaluation_Comparison_Matrix[cc[7]].values, width=0.3, label='RMSE (Testing)')\nplt.xticks(np.arange(5),EMC.index, rotation =35)\nplt.legend()\nplt.ylim([0,500000])\nplt.show()","metadata":{"papermill":{"duration":0.354305,"end_time":"2021-12-25T16:09:17.215446","exception":false,"start_time":"2021-12-25T16:09:16.861141","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T09:14:52.980212Z","iopub.execute_input":"2021-12-26T09:14:52.980565Z","iopub.status.idle":"2021-12-26T09:14:53.214098Z","shell.execute_reply.started":"2021-12-26T09:14:52.980529Z","shell.execute_reply":"2021-12-26T09:14:53.213327Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Inference:**\\\nLesser the RMSE, better the model! Also, provided the model should have close proximity with the training & testing scores. For this problem, it is can be said that polynomial regressions clearly overfitting the current problem. Surprisingly simple Multiple Linear Regression Model gave the best results. ","metadata":{"papermill":{"duration":0.11745,"end_time":"2021-12-25T16:09:17.455095","exception":false,"start_time":"2021-12-25T16:09:17.337645","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---","metadata":{"papermill":{"duration":0.121421,"end_time":"2021-12-25T16:09:17.696001","exception":false,"start_time":"2021-12-25T16:09:17.57458","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <center> 7. Project Outcomes & Conclusions","metadata":{"papermill":{"duration":0.122387,"end_time":"2021-12-25T16:09:17.942609","exception":false,"start_time":"2021-12-25T16:09:17.820222","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Here are some of the key outcomes of the project:\n- The Dataset was quiet small with just 6435 samples & after preprocessing 7.5% of the datasamples were dropped. \n- Visualising the distribution of data & their relationships, helped us to get some insights on the feature-set.\n- The features had high multicollinearity, hence in Feature Extraction step, we shortlisted the appropriate features with VIF Technique.\n- Testing multiple algorithms with default hyperparamters gave us some understanding for various models performance on this specific dataset.\n- It is safe to use multiple regression algorithm performed better than other algorithms, as their scores were quiet comparable & also they're more generalisable.","metadata":{"papermill":{"duration":0.125565,"end_time":"2021-12-25T16:09:18.194219","exception":false,"start_time":"2021-12-25T16:09:18.068654","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#<<<--------------------------------------------THE END------------------------------------------------>>>","metadata":{"papermill":{"duration":0.129612,"end_time":"2021-12-25T16:09:18.444633","exception":false,"start_time":"2021-12-25T16:09:18.315021","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-26T08:54:26.034064Z","iopub.execute_input":"2021-12-26T08:54:26.034423Z","iopub.status.idle":"2021-12-26T08:54:26.039823Z","shell.execute_reply.started":"2021-12-26T08:54:26.034374Z","shell.execute_reply":"2021-12-26T08:54:26.038722Z"},"trusted":true},"outputs":[],"execution_count":null}]}